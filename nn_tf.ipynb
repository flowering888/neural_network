{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification, make_moons, make_circles, make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "seed = 20181122\n",
    "samples = 2000\n",
    "is_liner = 0 # 0.linear(default), 1.blobs, 2.moons, 3.circles\n",
    "features = 2 # 特征数量\n",
    "n_classes = 3\n",
    "if is_liner in [1, 2, 3]:\n",
    "    n_classes = 2\n",
    "if is_liner == 0:\n",
    "    data, label = make_classification(n_features=features,\n",
    "                                      n_clusters_per_class=1, \n",
    "                                      n_samples=samples,\n",
    "                                      n_informative=features,\n",
    "                                      n_redundant=0,\n",
    "                                      n_repeated=0,\n",
    "                                      n_classes=n_classes)\n",
    "elif is_liner == 1:\n",
    "    data, label = make_blobs(n_samples=samples, n_features=features, centers=2, random_state=seed)\n",
    "elif is_liner == 2:\n",
    "    data, label = make_moons(n_samples=samples, noise=0.1, random_state=seed) # 月牙形状数据集\n",
    "elif is_liner == 3:\n",
    "    data, label = make_circles(n_samples=samples, noise=0.1, factor=0.4, random_state=seed) # 圆形数据集\n",
    "label = label.reshape((len(label), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_classes >= 2:\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    ohe = OneHotEncoder()\n",
    "    y_train = ohe.fit_transform(y_train).todense()\n",
    "    y_test = ohe.transform(y_test).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 计算训练集合上的均值 最大值 最小值 用来归一化\n",
    "mean = np.mean(X_train, axis=0)\n",
    "maxium = np.max(X_train, axis=0)\n",
    "minium = np.min(X_train, axis=0)\n",
    "\n",
    "# 归一化\n",
    "def normalizition(X, maxium=maxium, minium=minium, mean=mean):\n",
    "    return (X - mean) / (maxium - minium)\n",
    "\n",
    "X_train = normalizition(X_train)\n",
    "X_test = normalizition(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_layer(inputs, in_size, out_size, activation_function=tf.nn.relu):\n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(X):\n",
    "    global outputs\n",
    "    pred_y = sess.run(outputs, feed_dict={xs:X})\n",
    "    return pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 绘制决策边界\n",
    "def plot_decision_boundary(pred_func, X, y):\n",
    "    # 设定最大最小值，附加一点点边缘填充\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    h = 0.01\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    # 用预测函数预测一下\n",
    "    Z = pred_func(np.c_[xx.ravel(), yy.ravel()])\n",
    "    # 返回的是概率，转成类别\n",
    "    if n_classes == 1:\n",
    "        Z = (Z > 0.5).astype(np.int)\n",
    "    else:\n",
    "        Z = np.argmax(Z, axis=1)\n",
    "        Z = Z.reshape((len(Z), 1))\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    # 然后画出图\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=np.array(np.argmax(y, axis=1)).reshape((y.shape[0], )), cmap=plt.cm.Spectral)\n",
    "#     plt.scatter(X[:, 0], X[:, 1], c=y.reshape((y.shape[0], )), cmap=plt.cm.Spectral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# metric\n",
    "def accuracy(label, pred_y):\n",
    "    return np.mean(label == (pred_y > 0.5).astype(np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = tf.placeholder(tf.float32, [None, features])\n",
    "ys = tf.placeholder(tf.float32, [None, n_classes])\n",
    "nodes = 20 # 每层节点数\n",
    "# 输入层\n",
    "l1 = add_layer(xs, features, nodes)\n",
    "# 隐藏层\n",
    "l2 = add_layer(l1, nodes, nodes)\n",
    "# 输出层, 默认用sigmoid激活, 二分类\n",
    "outputs = add_layer(l2, nodes, n_classes, activation_function=tf.nn.sigmoid)\n",
    "\n",
    "# 下面使用tf自带的dense层\n",
    "# l1 = tf.layers.dense(xs, nodes, tf.nn.relu)\n",
    "# l2 = tf.layers.dense(l1, nodes, tf.nn.relu)\n",
    "# outputs = tf.layers.dense(l2, 1, tf.nn.sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "setting = {'epochs':3000,  # 迭代次数\n",
    "           'lr':0.001, # 学习率\n",
    "           'early_stopping':300, # 早停次数 \n",
    "           'current_epoch':0, # 当前轮次\n",
    "           'best_score':-np.inf}\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_metric = []\n",
    "test_metric = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# 清空上一次保存的内容\n",
    "model_path = './model/'\n",
    "[os.remove(f'{model_path}{i}') for i in os.listdir(model_path) if not i.startswith('.')]\n",
    "# 交叉熵loss\n",
    "loss = tf.losses.sigmoid_cross_entropy(ys, outputs)\n",
    "# loss = tf.losses.softmax_cross_entropy(ys, outputs)\n",
    "# 优化器 这里用的是Adam,tf.train下还有别的优化器\n",
    "train_step = tf.train.AdamOptimizer(setting['lr']).minimize(loss)\n",
    "# important step\n",
    "init = tf.global_variables_initializer()\n",
    "sess= tf.Session()\n",
    "sess.run(init)\n",
    "# 保存模型 max_to_keep 只保存一个模型\n",
    "saver = tf.train.Saver(max_to_keep=1)\n",
    "for i in range(setting['epochs']):\n",
    "    # training\n",
    "    sess.run(train_step, feed_dict={xs: X_train, ys: y_train})\n",
    "    # loss\n",
    "    train_loss.append(sess.run(loss, feed_dict={xs:X_train, ys:y_train}))\n",
    "    test_loss.append(sess.run(loss, feed_dict={xs:X_test, ys:y_test}))\n",
    "    # trian metric\n",
    "    pred_y = sess.run(outputs, feed_dict={xs:X_train})\n",
    "    train_metric.append(accuracy(y_train, pred_y))\n",
    "    # test metric\n",
    "    pred_y = sess.run(outputs, feed_dict={xs:X_test})\n",
    "    test_metric.append(accuracy(y_test, pred_y))\n",
    "    # early_stopping\n",
    "    if test_metric[-1] > setting['best_score']:\n",
    "        setting['best_score'] = test_metric[-1]\n",
    "        setting['current_epoch'] = 0\n",
    "        saver.save(sess, \"./model/self-model\", global_step=i)\n",
    "    setting['current_epoch'] += 1\n",
    "    if setting['early_stopping'] == setting['current_epoch']:\n",
    "        break\n",
    "    \n",
    "    acc = accuracy(label, pred_y)\n",
    "    if (i + 1) % 50 == 0:\n",
    "        # to see the step improvement\n",
    "        print('epoch:', i + 1,\n",
    "              'train loss:', train_loss[-1], \n",
    "              'test loss:', test_loss[-1],\n",
    "              'train acc:', train_metric[-1],\n",
    "              'test acc:', test_metric[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "meta_file = model_path + [i for i in os.listdir(model_path) if 'meta' in i][0]\n",
    "saver = tf.train.import_meta_graph(meta_file)\n",
    "saver.restore(sess, tf.train.latest_checkpoint(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_boundary(lambda x : predict(x), X_train, y_train)\n",
    "plt.title('train decision boundary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_boundary(lambda x : predict(x), X_test, y_test)\n",
    "plt.title('test decision boundary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss曲线\n",
    "plt.plot(list(range(len(train_loss))), train_loss, color='r')\n",
    "plt.plot(list(range(len(test_loss))), test_loss, color='g')\n",
    "plt.legend(['train_loss', 'test_loss'])\n",
    "plt.title('loss curve')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric 曲线\n",
    "plt.plot(list(range(len(train_metric))), train_metric, color='r')\n",
    "plt.plot(list(range(len(test_metric))), test_metric, color='g')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.title('accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Acc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_graph(df, title=\"\"):\n",
    "    t = df.query('label == 0')\n",
    "    x, y = t['f0'].values, t['f1'].values\n",
    "    plt.scatter(x, y)\n",
    "    t = df.query('label == 1')\n",
    "    x, y = t['f0'].values, t['f1'].values\n",
    "    plt.scatter(x, y)\n",
    "    plt.legend(['0', '1'])\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if nodes == 2:\n",
    "    t = pd.DataFrame(sess.run(l1, feed_dict={xs:X_train}), columns=[f'f{i}' for i in range(features)])\n",
    "    t['label'] = y_train\n",
    "    plot_graph(t)\n",
    "\n",
    "    t = pd.DataFrame(sess.run(l2, feed_dict={xs:X_train}), columns=[f'f{i}' for i in range(features)])\n",
    "    t['label'] = y_train\n",
    "    plot_graph(t)\n",
    "\n",
    "    t = pd.DataFrame(sess.run(outputs, feed_dict={xs:X_train}), columns=['f0'])\n",
    "    t['f1'] = y_train\n",
    "    t['label'] = y_train\n",
    "    plot_graph(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
